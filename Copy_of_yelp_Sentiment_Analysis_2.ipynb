{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of yelp_Sentiment_Analysis_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pnHjRl8zC1COIdjpFq_iwKe4CJ4H8fC8",
      "authorship_tag": "ABX9TyNMME+w/q0QXsPGRZN3Q+HE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayantc14/CDC-Intern-PS/blob/main/Copy_of_yelp_Sentiment_Analysis_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDfNz-jm4bfO"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff = pd.read_csv(\"/content/drive/MyDrive/yelp_dataset/yelp_smog_wordcount_refined2.csv\")"
      ],
      "metadata": {
        "id": "M8W6FPbpTI-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IVLAN9y4nRp"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/yelp_dataset/yelp_3cities_refined2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcKWw9p747i_"
      },
      "source": [
        "mydata = dff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "6RsSL9_45n6S",
        "outputId": "9c016dbd-b082-4013-f46c-b36078946a28"
      },
      "source": [
        "# Define a function to clean the text\n",
        "import re\n",
        "def clean(text):\n",
        "# Removes all special characters and numericals leaving the alphabets\n",
        "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
        "    return text\n",
        "\n",
        "# Cleaning the text in the review column\n",
        "mydata['Cleaned Reviews'] = mydata['text'].apply(clean)\n",
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_stars</th>\n",
              "      <th>useful_x</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>useful_y</th>\n",
              "      <th>fans</th>\n",
              "      <th>Smogscore</th>\n",
              "      <th>review_word_count</th>\n",
              "      <th>Cleaned Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2v0-gBcXethuNFT6rMGiRw</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>IGaRoRCHcYgOcAoRc-Ae5A</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>2019-01-01 00:00:38</td>\n",
              "      <td>187</td>\n",
              "      <td>6</td>\n",
              "      <td>8.3</td>\n",
              "      <td>166</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>T1wflZohQRZVb9SKQapfFA</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>uRqSoFwZr1lco5fYVbPyUw</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I went there with my boyfriends family  his tw...</td>\n",
              "      <td>2019-01-01 00:01:27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>79</td>\n",
              "      <td>I went there with my boyfriends family his two...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>uexKxrLmPO5iaXRT9TvWqQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>1eSNY9Csb9ajO7__ci2vTA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>2019-01-01 00:06:19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>251</td>\n",
              "      <td>Yes I am a fan of the food Ive tried more than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b4PgITSqSWoPhyJ-Mjko7Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>KYCpm1B9eIIgbPatCIcVkg</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>2019-01-01 00:08:26</td>\n",
              "      <td>328</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2EJpVjliJ6Ceijbz9HSpeQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>f1lLNjrLk4ETU2t_N7fHbA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>2019-01-01 00:08:49</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74</td>\n",
              "      <td>Fantastic authentic Italian food the pinsa has...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                    Cleaned Reviews\n",
              "0           0  ...  My friends and I decided to spontaneously stop...\n",
              "1           1  ...  I went there with my boyfriends family his two...\n",
              "2           2  ...  Yes I am a fan of the food Ive tried more than...\n",
              "3           3  ...  Im not a bubble tea connoisseur but Ive had it...\n",
              "4           4  ...  Fantastic authentic Italian food the pinsa has...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5WKF1GNQLsS",
        "outputId": "0c45bd9d-4fb9-44b9-f731-f94f31f6734c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "s59801HB5sct",
        "outputId": "97e97bd9-f088-4ef7-ea99-9e992ed8f6d6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# POS tagger dictionary\n",
        "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
        "def token_stop_pos(text):\n",
        "    tags = pos_tag(word_tokenize(text))\n",
        "    newlist = []\n",
        "    for word, tag in tags:\n",
        "        if word.lower() not in set(stopwords.words('english')):\n",
        "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
        "    return newlist\n",
        "\n",
        "mydata['POS tagged'] = mydata['Cleaned Reviews'].apply(token_stop_pos)\n",
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_stars</th>\n",
              "      <th>useful_x</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>useful_y</th>\n",
              "      <th>fans</th>\n",
              "      <th>Smogscore</th>\n",
              "      <th>review_word_count</th>\n",
              "      <th>Cleaned Reviews</th>\n",
              "      <th>POS tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2v0-gBcXethuNFT6rMGiRw</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>IGaRoRCHcYgOcAoRc-Ae5A</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>2019-01-01 00:00:38</td>\n",
              "      <td>187</td>\n",
              "      <td>6</td>\n",
              "      <td>8.3</td>\n",
              "      <td>166</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>[(friends, n), (decided, v), (spontaneously, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>T1wflZohQRZVb9SKQapfFA</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>uRqSoFwZr1lco5fYVbPyUw</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I went there with my boyfriends family  his tw...</td>\n",
              "      <td>2019-01-01 00:01:27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>79</td>\n",
              "      <td>I went there with my boyfriends family his two...</td>\n",
              "      <td>[(went, v), (boyfriends, n), (family, n), (two...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>uexKxrLmPO5iaXRT9TvWqQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>1eSNY9Csb9ajO7__ci2vTA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>2019-01-01 00:06:19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>251</td>\n",
              "      <td>Yes I am a fan of the food Ive tried more than...</td>\n",
              "      <td>[(Yes, None), (fan, n), (food, n), (Ive, n), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b4PgITSqSWoPhyJ-Mjko7Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>KYCpm1B9eIIgbPatCIcVkg</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>2019-01-01 00:08:26</td>\n",
              "      <td>328</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>[(Im, n), (bubble, a), (tea, n), (connoisseur,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2EJpVjliJ6Ceijbz9HSpeQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>f1lLNjrLk4ETU2t_N7fHbA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>2019-01-01 00:08:49</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74</td>\n",
              "      <td>Fantastic authentic Italian food the pinsa has...</td>\n",
              "      <td>[(Fantastic, a), (authentic, a), (Italian, a),...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         POS tagged\n",
              "0           0  ...  [(friends, n), (decided, v), (spontaneously, r...\n",
              "1           1  ...  [(went, v), (boyfriends, n), (family, n), (two...\n",
              "2           2  ...  [(Yes, None), (fan, n), (food, n), (Ive, n), (...\n",
              "3           3  ...  [(Im, n), (bubble, a), (tea, n), (connoisseur,...\n",
              "4           4  ...  [(Fantastic, a), (authentic, a), (Italian, a),...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YorTV0E1RKNY"
      },
      "source": [
        "**Text Blob**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "nvdxdXJNP-6A",
        "outputId": "1da5906d-7c67-460d-a070-11ffa17bd7d9"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize(pos_data):\n",
        "    lemma_rew = \" \"\n",
        "    for word, pos in pos_data:\n",
        "        if not pos:\n",
        "            lemma = word\n",
        "            lemma_rew = lemma_rew + \" \" + lemma\n",
        "        else:\n",
        "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
        "            lemma_rew = lemma_rew + \" \" + lemma\n",
        "    return lemma_rew\n",
        "\n",
        "mydata['Lemma'] = mydata['POS tagged'].apply(lemmatize)\n",
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_stars</th>\n",
              "      <th>useful_x</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>useful_y</th>\n",
              "      <th>fans</th>\n",
              "      <th>Smogscore</th>\n",
              "      <th>review_word_count</th>\n",
              "      <th>Cleaned Reviews</th>\n",
              "      <th>POS tagged</th>\n",
              "      <th>Lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2v0-gBcXethuNFT6rMGiRw</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>IGaRoRCHcYgOcAoRc-Ae5A</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>2019-01-01 00:00:38</td>\n",
              "      <td>187</td>\n",
              "      <td>6</td>\n",
              "      <td>8.3</td>\n",
              "      <td>166</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>[(friends, n), (decided, v), (spontaneously, r...</td>\n",
              "      <td>friend decide spontaneously stop Mr Dooleys ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>T1wflZohQRZVb9SKQapfFA</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>uRqSoFwZr1lco5fYVbPyUw</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I went there with my boyfriends family  his tw...</td>\n",
              "      <td>2019-01-01 00:01:27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>79</td>\n",
              "      <td>I went there with my boyfriends family his two...</td>\n",
              "      <td>[(went, v), (boyfriends, n), (family, n), (two...</td>\n",
              "      <td>go boyfriend family two brother wife kid def...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>uexKxrLmPO5iaXRT9TvWqQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>1eSNY9Csb9ajO7__ci2vTA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>2019-01-01 00:06:19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>251</td>\n",
              "      <td>Yes I am a fan of the food Ive tried more than...</td>\n",
              "      <td>[(Yes, None), (fan, n), (food, n), (Ive, n), (...</td>\n",
              "      <td>Yes fan food Ive try Chinese American restau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b4PgITSqSWoPhyJ-Mjko7Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>KYCpm1B9eIIgbPatCIcVkg</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>2019-01-01 00:08:26</td>\n",
              "      <td>328</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>[(Im, n), (bubble, a), (tea, n), (connoisseur,...</td>\n",
              "      <td>Im bubble tea connoisseur Ive couple place a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2EJpVjliJ6Ceijbz9HSpeQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>f1lLNjrLk4ETU2t_N7fHbA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>2019-01-01 00:08:49</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74</td>\n",
              "      <td>Fantastic authentic Italian food the pinsa has...</td>\n",
              "      <td>[(Fantastic, a), (authentic, a), (Italian, a),...</td>\n",
              "      <td>Fantastic authentic Italian food pinsa crunc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                              Lemma\n",
              "0           0  ...    friend decide spontaneously stop Mr Dooleys ...\n",
              "1           1  ...    go boyfriend family two brother wife kid def...\n",
              "2           2  ...    Yes fan food Ive try Chinese American restau...\n",
              "3           3  ...    Im bubble tea connoisseur Ive couple place a...\n",
              "4           4  ...    Fantastic authentic Italian food pinsa crunc...\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj6XW-ehQxJB"
      },
      "source": [
        "from textblob import TextBlob\n",
        "# function to calculate subjectivity\n",
        "def getSubjectivity(review):\n",
        "    return TextBlob(review).sentiment.subjectivity\n",
        "    # function to calculate polarity\n",
        "def getPolarity(review):\n",
        "    return TextBlob(review).sentiment.polarity\n",
        "\n",
        "# function to analyze the reviews\n",
        "def analysis(score):\n",
        "    if score < 0:\n",
        "        return 'Negative'\n",
        "    elif score == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RBIzVZKQ9L5"
      },
      "source": [
        "fin_data = pd.DataFrame(mydata[['text', 'Lemma']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "yb3AE6exRBOv",
        "outputId": "a1563eef-e80f-4362-a7f9-cbf6a655f9a1"
      },
      "source": [
        "# fin_data['Subjectivity'] = fin_data['Lemma'].apply(getSubjectivity) \n",
        "mydata['Polarity'] = mydata['Lemma'].apply(getPolarity) \n",
        "mydata['Analysis_TextBlob'] = mydata['Polarity'].apply(analysis)\n",
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_stars</th>\n",
              "      <th>useful_x</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>useful_y</th>\n",
              "      <th>fans</th>\n",
              "      <th>Smogscore</th>\n",
              "      <th>review_word_count</th>\n",
              "      <th>Cleaned Reviews</th>\n",
              "      <th>POS tagged</th>\n",
              "      <th>Lemma</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Analysis_TextBlob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2v0-gBcXethuNFT6rMGiRw</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>IGaRoRCHcYgOcAoRc-Ae5A</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>2019-01-01 00:00:38</td>\n",
              "      <td>187</td>\n",
              "      <td>6</td>\n",
              "      <td>8.3</td>\n",
              "      <td>166</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>[(friends, n), (decided, v), (spontaneously, r...</td>\n",
              "      <td>friend decide spontaneously stop Mr Dooleys ...</td>\n",
              "      <td>0.301105</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>T1wflZohQRZVb9SKQapfFA</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>uRqSoFwZr1lco5fYVbPyUw</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I went there with my boyfriends family  his tw...</td>\n",
              "      <td>2019-01-01 00:01:27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>79</td>\n",
              "      <td>I went there with my boyfriends family his two...</td>\n",
              "      <td>[(went, v), (boyfriends, n), (family, n), (two...</td>\n",
              "      <td>go boyfriend family two brother wife kid def...</td>\n",
              "      <td>0.456250</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>uexKxrLmPO5iaXRT9TvWqQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>1eSNY9Csb9ajO7__ci2vTA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>2019-01-01 00:06:19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>251</td>\n",
              "      <td>Yes I am a fan of the food Ive tried more than...</td>\n",
              "      <td>[(Yes, None), (fan, n), (food, n), (Ive, n), (...</td>\n",
              "      <td>Yes fan food Ive try Chinese American restau...</td>\n",
              "      <td>0.050208</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b4PgITSqSWoPhyJ-Mjko7Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>KYCpm1B9eIIgbPatCIcVkg</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>2019-01-01 00:08:26</td>\n",
              "      <td>328</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>[(Im, n), (bubble, a), (tea, n), (connoisseur,...</td>\n",
              "      <td>Im bubble tea connoisseur Ive couple place a...</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2EJpVjliJ6Ceijbz9HSpeQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>f1lLNjrLk4ETU2t_N7fHbA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>2019-01-01 00:08:49</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74</td>\n",
              "      <td>Fantastic authentic Italian food the pinsa has...</td>\n",
              "      <td>[(Fantastic, a), (authentic, a), (Italian, a),...</td>\n",
              "      <td>Fantastic authentic Italian food pinsa crunc...</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             business_id  ...  Polarity Analysis_TextBlob\n",
              "0           0  2v0-gBcXethuNFT6rMGiRw  ...  0.301105          Positive\n",
              "1           1  T1wflZohQRZVb9SKQapfFA  ...  0.456250          Positive\n",
              "2           2  uexKxrLmPO5iaXRT9TvWqQ  ...  0.050208          Positive\n",
              "3           3  b4PgITSqSWoPhyJ-Mjko7Q  ...  0.263889          Positive\n",
              "4           4  2EJpVjliJ6Ceijbz9HSpeQ  ...  0.360000          Positive\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PixekhGRovjI",
        "outputId": "5532c770-69d2-4820-cdc3-dab3638c88d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_stars</th>\n",
              "      <th>useful_x</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>useful_y</th>\n",
              "      <th>fans</th>\n",
              "      <th>Smogscore</th>\n",
              "      <th>review_word_count</th>\n",
              "      <th>Cleaned Reviews</th>\n",
              "      <th>POS tagged</th>\n",
              "      <th>Lemma</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Analysis_TextBlob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2v0-gBcXethuNFT6rMGiRw</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>IGaRoRCHcYgOcAoRc-Ae5A</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>2019-01-01 00:00:38</td>\n",
              "      <td>187</td>\n",
              "      <td>6</td>\n",
              "      <td>8.3</td>\n",
              "      <td>166</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>[(friends, n), (decided, v), (spontaneously, r...</td>\n",
              "      <td>friend decide spontaneously stop Mr Dooleys ...</td>\n",
              "      <td>0.301105</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>T1wflZohQRZVb9SKQapfFA</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>uRqSoFwZr1lco5fYVbPyUw</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I went there with my boyfriends family  his tw...</td>\n",
              "      <td>2019-01-01 00:01:27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>79</td>\n",
              "      <td>I went there with my boyfriends family his two...</td>\n",
              "      <td>[(went, v), (boyfriends, n), (family, n), (two...</td>\n",
              "      <td>go boyfriend family two brother wife kid def...</td>\n",
              "      <td>0.456250</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>uexKxrLmPO5iaXRT9TvWqQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>1eSNY9Csb9ajO7__ci2vTA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>2019-01-01 00:06:19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>251</td>\n",
              "      <td>Yes I am a fan of the food Ive tried more than...</td>\n",
              "      <td>[(Yes, None), (fan, n), (food, n), (Ive, n), (...</td>\n",
              "      <td>Yes fan food Ive try Chinese American restau...</td>\n",
              "      <td>0.050208</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b4PgITSqSWoPhyJ-Mjko7Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>KYCpm1B9eIIgbPatCIcVkg</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>2019-01-01 00:08:26</td>\n",
              "      <td>328</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>[(Im, n), (bubble, a), (tea, n), (connoisseur,...</td>\n",
              "      <td>Im bubble tea connoisseur Ive couple place a...</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2EJpVjliJ6Ceijbz9HSpeQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>f1lLNjrLk4ETU2t_N7fHbA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>2019-01-01 00:08:49</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74</td>\n",
              "      <td>Fantastic authentic Italian food the pinsa has...</td>\n",
              "      <td>[(Fantastic, a), (authentic, a), (Italian, a),...</td>\n",
              "      <td>Fantastic authentic Italian food pinsa crunc...</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197944</th>\n",
              "      <td>197944</td>\n",
              "      <td>jPzZkfLB06MRbXGTQTjPhQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>WK5f8tVkdMGsYEL-Agkf4A</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>Delicious They have a more limited takeout men...</td>\n",
              "      <td>2021-01-28 13:30:50</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>106</td>\n",
              "      <td>Delicious They have a more limited takeout men...</td>\n",
              "      <td>[(Delicious, n), (limited, a), (takeout, n), (...</td>\n",
              "      <td>Delicious limited takeout menu right pandemi...</td>\n",
              "      <td>0.220952</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197945</th>\n",
              "      <td>197945</td>\n",
              "      <td>IqyqfQFnBsOIReGrcgaYhA</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>DJctK3XMg_8-zFZYY8puKA</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Store is a little hard to find since it is hid...</td>\n",
              "      <td>2021-01-28 13:40:31</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>Store is a little hard to find since it is hid...</td>\n",
              "      <td>[(Store, n), (little, a), (hard, a), (find, v)...</td>\n",
              "      <td>Store little hard find since hide little foo...</td>\n",
              "      <td>-0.038889</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197946</th>\n",
              "      <td>197946</td>\n",
              "      <td>9cGMeGzjfhH85M-Bp9rY9Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>HCyiSGsE49t_TQTy-MGnFQ</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>I get lunch here at least once a week the Nips...</td>\n",
              "      <td>2021-01-28 14:35:30</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>I get lunch here at least once a week the Nips...</td>\n",
              "      <td>[(get, v), (lunch, a), (least, a), (week, n), ...</td>\n",
              "      <td>get lunch least week Nipsey Hussle killer sh...</td>\n",
              "      <td>-0.188889</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197947</th>\n",
              "      <td>197947</td>\n",
              "      <td>Ro35BZZpDcf92BOKvkhoag</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>9CGJqQFC88oX7ZpjQMEn0g</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife loves this place She could eat the man...</td>\n",
              "      <td>2021-01-28 15:08:08</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>29</td>\n",
              "      <td>My wife loves this place She could eat the man...</td>\n",
              "      <td>[(wife, n), (loves, v), (place, n), (could, No...</td>\n",
              "      <td>wife love place could eat mango chicken ever...</td>\n",
              "      <td>0.278333</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197948</th>\n",
              "      <td>197948</td>\n",
              "      <td>DZm67Anqn1IQTB9iGvw4Fw</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>QBqlznZ5H0Dh2cetctJPfA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Food was fine drinks were good Not a typical b...</td>\n",
              "      <td>2021-01-28 15:21:57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>43</td>\n",
              "      <td>Food was fine drinks were good Not a typical b...</td>\n",
              "      <td>[(Food, n), (fine, a), (drinks, n), (good, a),...</td>\n",
              "      <td>Food fine drink good typical brewery hop oka...</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197949 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0             business_id  ...  Polarity Analysis_TextBlob\n",
              "0                0  2v0-gBcXethuNFT6rMGiRw  ...  0.301105          Positive\n",
              "1                1  T1wflZohQRZVb9SKQapfFA  ...  0.456250          Positive\n",
              "2                2  uexKxrLmPO5iaXRT9TvWqQ  ...  0.050208          Positive\n",
              "3                3  b4PgITSqSWoPhyJ-Mjko7Q  ...  0.263889          Positive\n",
              "4                4  2EJpVjliJ6Ceijbz9HSpeQ  ...  0.360000          Positive\n",
              "...            ...                     ...  ...       ...               ...\n",
              "197944      197944  jPzZkfLB06MRbXGTQTjPhQ  ...  0.220952          Positive\n",
              "197945      197945  IqyqfQFnBsOIReGrcgaYhA  ... -0.038889          Negative\n",
              "197946      197946  9cGMeGzjfhH85M-Bp9rY9Q  ... -0.188889          Negative\n",
              "197947      197947  Ro35BZZpDcf92BOKvkhoag  ...  0.278333          Positive\n",
              "197948      197948  DZm67Anqn1IQTB9iGvw4Fw  ...  0.261905          Positive\n",
              "\n",
              "[197949 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mydata.to_csv(\"/content/drive/MyDrive/yelp_dataset/textblob.csv\")"
      ],
      "metadata": {
        "id": "0xnGw5QjoWST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-JEm-ppRYM6"
      },
      "source": [
        "**Vader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x02UGHcQfI7D",
        "outputId": "644e06d6-4e87-4bf1-8f10-153623a708fb"
      },
      "source": [
        "pip install vaderSentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "n_NtE8blRaJY",
        "outputId": "5287aef7-7f76-42bc-cb47-0cd7358513c9"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "# function to calculate vader sentiment\n",
        "def vadersentimentanalysis(review):\n",
        "    vs = analyzer.polarity_scores(review)\n",
        "    return vs['compound']\n",
        "mydata['Vader Sentiment'] = mydata['Lemma'].apply(vadersentimentanalysis)\n",
        "# function to analyse\n",
        "def vader_analysis(compound):\n",
        "    if compound >= 0.5:\n",
        "        return 'Positive'\n",
        "    elif compound <= -0.5 :\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "mydata['Vader Analysis'] = mydata['Vader Sentiment'].apply(vader_analysis)\n",
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_stars</th>\n",
              "      <th>useful_x</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>useful_y</th>\n",
              "      <th>fans</th>\n",
              "      <th>Smogscore</th>\n",
              "      <th>review_word_count</th>\n",
              "      <th>Cleaned Reviews</th>\n",
              "      <th>POS tagged</th>\n",
              "      <th>Lemma</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Analysis_TextBlob</th>\n",
              "      <th>Vader Sentiment</th>\n",
              "      <th>Vader Analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2v0-gBcXethuNFT6rMGiRw</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>IGaRoRCHcYgOcAoRc-Ae5A</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>2019-01-01 00:00:38</td>\n",
              "      <td>187</td>\n",
              "      <td>6</td>\n",
              "      <td>8.3</td>\n",
              "      <td>166</td>\n",
              "      <td>My friends and I decided to spontaneously stop...</td>\n",
              "      <td>[(friends, n), (decided, v), (spontaneously, r...</td>\n",
              "      <td>friend decide spontaneously stop Mr Dooleys ...</td>\n",
              "      <td>0.301105</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9889</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>T1wflZohQRZVb9SKQapfFA</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>uRqSoFwZr1lco5fYVbPyUw</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I went there with my boyfriends family  his tw...</td>\n",
              "      <td>2019-01-01 00:01:27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>79</td>\n",
              "      <td>I went there with my boyfriends family his two...</td>\n",
              "      <td>[(went, v), (boyfriends, n), (family, n), (two...</td>\n",
              "      <td>go boyfriend family two brother wife kid def...</td>\n",
              "      <td>0.456250</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9618</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>uexKxrLmPO5iaXRT9TvWqQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>1eSNY9Csb9ajO7__ci2vTA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>2019-01-01 00:06:19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>251</td>\n",
              "      <td>Yes I am a fan of the food Ive tried more than...</td>\n",
              "      <td>[(Yes, None), (fan, n), (food, n), (Ive, n), (...</td>\n",
              "      <td>Yes fan food Ive try Chinese American restau...</td>\n",
              "      <td>0.050208</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.7723</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b4PgITSqSWoPhyJ-Mjko7Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>KYCpm1B9eIIgbPatCIcVkg</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>2019-01-01 00:08:26</td>\n",
              "      <td>328</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>[(Im, n), (bubble, a), (tea, n), (connoisseur,...</td>\n",
              "      <td>Im bubble tea connoisseur Ive couple place a...</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2EJpVjliJ6Ceijbz9HSpeQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>f1lLNjrLk4ETU2t_N7fHbA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>2019-01-01 00:08:49</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74</td>\n",
              "      <td>Fantastic authentic Italian food the pinsa has...</td>\n",
              "      <td>[(Fantastic, a), (authentic, a), (Italian, a),...</td>\n",
              "      <td>Fantastic authentic Italian food pinsa crunc...</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9307</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             business_id  ... Vader Sentiment Vader Analysis\n",
              "0           0  2v0-gBcXethuNFT6rMGiRw  ...          0.9889       Positive\n",
              "1           1  T1wflZohQRZVb9SKQapfFA  ...          0.9618       Positive\n",
              "2           2  uexKxrLmPO5iaXRT9TvWqQ  ...          0.7723       Positive\n",
              "3           3  b4PgITSqSWoPhyJ-Mjko7Q  ...          0.8519       Positive\n",
              "4           4  2EJpVjliJ6Ceijbz9HSpeQ  ...          0.9307       Positive\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata.to_csv(\"/content/drive/MyDrive/yelp_dataset/textblob_vader_refined2.csv\")"
      ],
      "metadata": {
        "id": "sIqMOkBfp0fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZb0A7QrguxK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}